
<p align="center">
  <img src="https://github.com/cristos34/PF-MigracionEnAmerica/blob/main/src/portada.PNG">
</p>

## Enlaces de Interés

+ [Tableros de control](https://lookerstudio.google.com/reporting/31a7a9b6-0a53-44bb-bd06-6875bf5a3a1f/page/p_9l8kji675c)
+ [Modelo de IA deployado en Streamlit](https://cristos34-pf-streamlitmigraciondeployen-iostreamlitnewml-14juu5.streamlit.app/)  
+ [Demo ETL en GCP](https://youtu.be/HIee2ShqlPQ) 

## DatosEstratégicos
### ¿Quienes somos?

Somos **DatosEstratégicos** una consultora con amplia experiencia e innovación en diferentes sectores de la industria.

Nos enfocamos en brindar soluciones de análisis de datos, inteligencia de negocios y modelado predictivo de datos innovadores y personalizadas para nuestros clientes, y trabajamos estrechamente con ellos para identificar las habilidades y conocimientos clave que serán necesarios en el futuro. 

### Nuestro equipo
Nuestro equipo de expertos está constantemente actualizado en las últimas tendencias y tecnologías del mercado laboral para brindar soluciones prácticas y efectivas para nuestros clientes. En DatosEstratégicos , estamos comprometidos con el éxito de nuestros clientes. 

+ [Alexander Rios](https://github.com/Alekzander10) - Data Analyst
+ [Cristian Andres](https://github.com/cristos34) - Data Engineer
+ [Ricardo Soria](https://github.com/RickDev31) - Data Scientist
+ [Santiago Zapata](https://github.com/santizapata5) - Data Engineer

### Dirección de proyecto
+ [Maico Bernal](https://github.com/maicobernal) - Scrum Master

## Entendimiento de la problemática

La migración es un fenómeno complejo que puede tener tanto impactos positivos como negativos en los países de origen y destino, especialmente en términos económicos. 

En América, la migración es un tema especialmente relevante debido a la alta tasa de migración en la región y a los flujos migratorios hacia Estados Unidos. Por ejemplo, la migración hacia Estados Unidos ha tenido un impacto significativo en la economía de México, ya que muchos trabajadores mexicanos envían remesas a sus familias en casa. En Colombia, la migración ha sido un tema importante debido al conflicto armado interno y a la llegada de migrantes venezolanos. En Argentina, los cambios en la política migratoria han reducido los flujos migratorios hacia el país, lo que puede tener un impacto significativo en la economía argentina. En Perú y Chile, la presencia de migrantes venezolanos puede afectar a los sectores de empleo y servicios públicos. 

En DatosEstratégicos, nuestra misión es emplear tecnología de vanguardia y metodologías avanzadas para recopilar, procesar y analizar los datos sobre el estudio de la "Migración en América : desigualdad económica y desplazamiento forzado" sobre los desafíos y oportunidades que surgen de los flujos migratorios y en colaboración con nuestros clientes, diseñamos soluciones personalizadas que aborden esta problemática y generen un impacto positivo en la sociedad y la disposión de la solución de datos por parte de Migrantes Sin Fronteras.

## Propuesta de proyecto

El equipo de trabajo de DatosEstratégicos da a conocer un completo estudio y solución acerca de la "Migración en América: desigualdad económica y desplazamiento forzado" para la organización internacional Migrantes Sin Fronteras.

### Objetivos

+ Objetivos Generales

  + Analizar los flujos migratorios en América con mayor incidencia en países como Estados Unidos, México, Colombia, Argentina, Perú, Chile y Venezuela.
  + Comprender cómo los factores económicos influyen en los flujos migratorios tanto en los países de origen como de destino.
  + Identificar las principales tendencias y patrones de los flujos migratorios en los países mencionados.

+ Objetivos específicos

  + Analizar la tendencia de cómo el desplazamiento forzado impacta los patrones de migración en los países de origen como de destino.
  + Identificar los principales factores económicos que influyen en los flujos migratorios. 
  + Identificar qué países son más vulnerables tienen mayor incidencia de migrar. 
  + Estudiar los principales destinos de los migrantes y analizar las razones detrás de sus elecciones.
  + Predecir futuros patrones de migración de acuerdo a las condiciones socioeconómico actuales.

### Alcance

+ Negocio objetivo: ONG internacinal
+ Área geográfica: América 
+ Periodo de información: 2007-2022
+ Fuente de información: Banco Mundial, ONU, Organización Internacional para las Migraciones, Centro de Monitoreo de Desplazamiento

### Limitaciones
+ Barreras tecnológicas 
+ Todo área geográfica fuera de América
+ Cualquier otra actividad que demande mayor recurso de los ya mencionados

## KPIs
+ **Tasa de migración neta**: mide la diferencia entre el número de personas que abandonan un país y el número de personas que llegan a este. La meta es reducir la tasa en un 10% en los próximos dos años mediante programas que incentiven a la población a permanecer en el país.

+ **Tasa de desplazamiento forzado**: mide la cantidad de personas que han sido desplazadas forzosamente debido a conflictos armados, desastres naturales u otras causas. La meta es reducir la tasa de desplazamiento forzado en un 20% en los próximos cinco años mediante la implementación de medidas de protección a los derechos humanos.

+ **Indice de vulnerabilidad migratoria**: mide la capacidad de los países para hacer frente a los flujos migratorios. La meta es mejorar este índice en un 10% en los próximos tres años.

+ **Porcentaje de migrantes que envían remesas**: mide la capacidad de los países para retener a los trabajadores altamente capacitados en su territorio. La meta es mejorar este índice en un 15% en los próximos tres años mediante políticas y programas que incentiven la permanencia de este tipo de trabajadores en el país.

+ **Eficiencia operativa, Gestión ONG:**
Se refiere a la capacidad de la ONG para utilizar sus recursos de manera eficiente. Este KPI se mide como el porcentaje de recursos destinados a la misión principal de la ONG en comparación con los gastos generales y administrativos. La meta es aumentar el porcentaje de recursos destinados a la misión principal en un 5% en el plazo de un año.

<p align="center">
  <img src="https://github.com/cristos34/PF-MigracionEnAmerica/blob/main/src/KPI.JPG">
</p>

## Tableros de control

Se cuenta con varios tableros de control que pemitirán monitorear la situación social y económica de los países, así como uno para la gestión de la ONG.

### Tablero indicadores gestión ONG

<p align="center">
  <img src="https://github.com/cristos34/PF-MigracionEnAmerica/blob/main/src/gestion.JPG">
</p>

### Tablero indicadores económicos de los países

<p align="center">
  <img src="https://github.com/cristos34/PF-MigracionEnAmerica/blob/main/src/tablero%20economic.JPG">
</p>

### Tablero indicadores sociales de los países

<p align="center">
  <img src="https://github.com/cristos34/PF-MigracionEnAmerica/blob/main/src/tablero%20social.JPG">
</p>

### Índice de vulnerabilidad migratoria para monitorear países de especial atención

<p align="center">
  <img src="https://github.com/cristos34/PF-MigracionEnAmerica/blob/main/src/vuln.JPG">
</p>

### Performance del modelo

Predecir posibles grupos de migrantes para el próximo año de acuerdo a las condiciones socioeconómico futuro con el fin de disponer una solución que genere un impacto positivo a la población migrante, a través de la implementación de programas que beneficien a dicha población.

### Metodología de trabajo

Utilizamos Scrum como metodología de trabajo para trabajar de .manera más eficiente y colaborativa, enfocados en la entrega de valor constante y adaptarnos a los cambios en los requisitos y objetivos del proyecto.

<p align="center">
  <img src="https://i.ibb.co/4TJcLRk/scrum.png">
</p>

### Stack tecnológico

<p align="center">
  <img src="https://i.ibb.co/8xQdvp7/tech.png">
</p>

## Cronología general
### Diagrama de Gantt
Se emplea el uso del Diagrama de Gantt como herramienta que nos permite visualizar las actividades de progreso del proyecto y ajustar el plan según sea necesario.

<p align="center">
  <img src="https://github.com/cristos34/PF-MigracionEnAmerica/blob/main/src/ganttfinal.png">
</p>

## Documentacion Google Cloud Platform

En el presente documento se presentan los detalles técnicos del diseño de la base de datos relacional a implementar en nuestro Data Warehouse y los detalles de la estructuración del proyecto en Google Cloud Platform. Encontrarán algunos enlaces de interés, el diccionario de datos, el esquema entidad-relación, el diagrama del flujo de trabajo en GCP y el detalle del paso a paso realizado durante todo el proceso en la nube. 

## Diccionario de datos 

Se establece una descripción detallada de todas las tablas con base en los conjuntos de datos empleados. En el diccionario se puede observar los nombres de las tablas y de las columnas, el tipo de dato de cada columna, la descripción de cada variable, el uso de llaves primarias y foráneas, etc. En las siguientes imágenes se muestra la totalidad del diccionario de datos.

## Esquema ER (Entidad-Relación) 

Este es un modelo de datos que resulta útil para el diseño de la base de datos, ya que permite visualizar cómo se relacionan los datos antes de construir la estructura de la base de datos.

<p align="center">
  <img src="https://github.com/cristos34/PF-MigracionEnAmerica/blob/main/src/MODELO%20ER.jpeg">
</p>  

## Streamlit

Streamlit es un framework open source para la creación de aplicaciones web interactivas y basadas en datos. Está diseñado para facilitar la creación de aplicaciones de machine learning, visualización de datos y paneles de control de manera rápida y sencilla.

Esta herramienta se usó con el fin de visualizar los datos arrojados por los diferentes modelos de predicción que generaron para este proyecto de forma real y a tiempo, para conocer el [documento]([https://github.com/Alekzander10](https://github.com/cristos34/PF-MigracionEnAmerica/blob/main/StreamlitMigracionDeployEn-io/StreamlitNewML.py)), en el cual se manejaron diferentes librerías como son:

+ Streamlit
+ Numpy
+ Pandas
+ Pickle 
+ PIL
+ Scikit-Learn

## Carpeta StreamlitMigracionDeployEn-io

"Dentro de la carpeta StreamlitMigracionDeployEn-io, se encuentran los 4 archivos empleados para hacer el Deploy y visualizacion de los datos como son: Requirements.txt, Predicciones, Assets y el StreamlitNewML.py".

## Carpeta pipelines

"Dentro de la carpeta pipelines se encuentran los 2 archivos empleados para hacer el ETL y creación del DWH de forma automática. En el vídeo de demostración se explica el funcionamiento de los mismos".

## Justificación del uso de Google Cloud Platform

Decidimos realizar el proceso de ETL y Data Warehouse en la plataforma de Google Cloud debido a la flexibilidad y amplia gama de tecnologías que ofrece, muchas de ellas orientadas hacia los procesos de Big Data, Machine Learning, Data Analytics, entre otros. Luego también permite una fácil conexión entre diferentes herramientas incluyendo Looker Studio para la visualización.

Aparte de las ventajas mencionadas que ofrece Google Cloud Platform, realizar nuestro proceso de ETL nube también presenta muchas otras ventajas como:

**Accesibilidad remota**: es accesible desde cualquier ubicación tanto para el trabajo colaborativo del equipo de desarrollo como para el uso de la solución propuesta por parta de la fundación Migrantes Sin Fronteras.

**Costos**: permite un costo menor para el proyecto al no requerir infraestructuras costosas de hardware y software.
Seguridad: GCP brinda seguridad y protección a los datos, así como copias de seguridad automáticas y control de acceso, lo que mejora la seguridad del proyecto y reduce el riesgo de pérdida de datos.

**Las herramientas de Google Cloud Platform que vamos a emplear son las siguientes**:
Cloud Storage: es un servicio de almacenamiento en la nube integrado a las demás herramientas.

**Dataflow**: facilita la creación de pipelines (canalizaciones) de datos que pueden integrarse con otros servicios de Google Cloud y de terceros.
BigQuery: es un servicio de análisis de datos que permite almacenar y consultar grandes conjuntos de datos con una gran velocidad y facilidad. 
Cloud Functions: permite ejecutar código en respuesta a eventos específicos (trigger), como la carga de archivos en Cloud Storage.
Looker Studio: permite crear informes y dashboards a partir de los datos alojados en BigQuery.

**Vertex AI**: es un servicio de aprendizaje automático que permite crear, entrenar e implementar modelos de Machine Learning.

**Flujo de trabajo/arquitectura de los datos en Google Cloud Platform (resumen)**
Inicialmente se creará un bucket (herramienta de almacenamiento en la nube que funciona de forma similar a una carpeta) en el cual se alojarán el código de los pipelines y el data lake a donde llegarán los conjuntos de datos en crudo después de realizar la extracción.
Cuando estén subidos y listos los pipelines, se ejecutan mediante la terminal de Google Shell para que estos se encarguen de alojar los conjuntos de datos en el data lake y realizar unas transformaciones iniciales.

Luego mediante la herramienta BigQuery se tomarán estos datos desde el data lake para transformarlos y añadirlos a la base de datos (Data Warehouse).
Una vez se tengan los datos almacenados en el Data Warehouse, estos estarán disponibles para ser tomados por la herramienta de visualización Looker Studio para la posterior creación de un dashboard y otras herramientas de aprendizaje automático como es el caso de Vertex AI.
Adicionalmente, se emplearán funciones de Cloud Functions que permitan realizar la carga incremental de datos. A estas funciones se les define un activador o trigger para que se ejecuten de forma automática. En este caso el activador que se tomará es el de subir un archivo a un bucket.

**El proceso de carga incremental de datos con Apache Beam** 
Permite la adición de nuevos datos a una tabla existente sin perder los registros antiguos que ya se encuentran allí. Esto se logra mediante el uso de una clave de identificación única para cada registro en la tabla y comparando esta clave con los nuevos datos que se van a cargar. Si se encuentra una coincidencia, se actualiza el registro existente con los nuevos valores. De lo contrario, se agrega un nuevo registro a la tabla. Este enfoque garantiza que la tabla siempre contenga los datos más recientes y precisos. Además, al utilizar Apache Beam para realizar este proceso, se obtiene una solución escalable y fácilmente configurable para la carga incremental de grandes cantidades de datos en tiempo real.

**Descripción de la grafica**
En este diagrama, podemos ver que el proceso comienza con la lectura de los datos nuevos y antiguos. A continuación, se lleva a cabo una transformación que utiliza una clave de identificación única para comparar los nuevos datos con los existentes. Si se encuentra una coincidencia, se actualiza el registro existente; de lo contrario, se agrega un nuevo registro.

Después de la transformación, los datos actualizados se cargan en la tabla existente, manteniendo los datos antiguos que ya se encuentran allí. Este proceso se puede repetir de forma regular para mantener actualizada la tabla con los nuevos datos.  

<p align="center">
  <img src="https://github.com/cristos34/PF-MigracionEnAmerica/blob/main/src/arquitectura.JPG">
</p> 

